{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # 导入标准化模块"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# 定义神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)  # 第一个隐藏层\n",
    "        self.fc2 = nn.Linear(16, 8)           # 第二个隐藏层\n",
    "        self.fc3 = nn.Linear(8, output_size)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"使用版2012-2023-2个相关因素_2位小数.xlsx\")\n",
    "\n",
    "x, y = data.iloc[:,2:].to_numpy(), data.iloc[:,1].to_numpy().reshape(-1, 1)\n",
    "scaler = MinMaxScaler()  # 实例化\n",
    "X = scaler.fit_transform(x)  # 标准化特征\n",
    "Y = scaler.fit_transform(y)  # 标准化标签\n",
    "\n",
    "train_X, train_Y, val_X, val_Y = X[:-2], Y[:-2], X[-2:], Y[-2:]\n",
    "train_torch_data = TensorDataset(torch.FloatTensor(train_X), torch.FloatTensor(train_Y))\n",
    "val_torch_data = TensorDataset(torch.FloatTensor(val_X), torch.FloatTensor(val_Y))\n",
    "all_torch_data = TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y))\n",
    "\n",
    "train_loader = DataLoader(train_torch_data, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_torch_data, batch_size=1)\n",
    "all_loader = DataLoader(all_torch_data, batch_size=data.shape[0])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# 将数据分为输入和输出\n",
    "input_size = 2  # 2个输入\n",
    "output_size = 1  # 1个输出\n",
    "learning_rate = 1e-5 # 学习率\n",
    "\n",
    "bpnn = Net(input_size, output_size)\n",
    "\n",
    "optimizer = optim.Adam(bpnn.parameters(), learning_rate)  # 使用Adam算法更新参数\n",
    "criteon = torch.nn.MSELoss()  # 损失函数，回归问题采用均方误差"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 , Loss: 0.18516463041305542\n",
      "Epoch 200 , Loss: 0.2989436686038971\n",
      "Epoch 300 , Loss: 0.08429031819105148\n",
      "Epoch 400 , Loss: 0.08598598092794418\n",
      "Epoch 500 , Loss: 0.08052727580070496\n",
      "Epoch 600 , Loss: 0.258340984582901\n",
      "Epoch 700 , Loss: 0.05537844076752663\n",
      "Epoch 800 , Loss: 0.13518428802490234\n",
      "Epoch 900 , Loss: 0.05064769834280014\n",
      "Epoch 1000 , Loss: 0.2881772220134735\n",
      "Epoch 1100 , Loss: 0.002057106466963887\n",
      "Epoch 1200 , Loss: 0.04716426879167557\n",
      "Epoch 1300 , Loss: 0.043597035109996796\n",
      "Epoch 1400 , Loss: 0.007623428478837013\n",
      "Epoch 1500 , Loss: 0.17598359286785126\n",
      "Epoch 1600 , Loss: 0.05194465443491936\n",
      "Epoch 1700 , Loss: 0.02100137062370777\n",
      "Epoch 1800 , Loss: 0.0353197380900383\n",
      "Epoch 1900 , Loss: 0.031203273683786392\n",
      "Epoch 2000 , Loss: 0.013626371510326862\n",
      "Epoch 2100 , Loss: 0.014673823490738869\n",
      "Epoch 2200 , Loss: 0.020776286721229553\n",
      "Epoch 2300 , Loss: 0.10446538776159286\n",
      "Epoch 2400 , Loss: 0.017527727410197258\n",
      "Epoch 2500 , Loss: 0.01863020285964012\n",
      "Epoch 2600 , Loss: 0.02824423462152481\n",
      "Epoch 2700 , Loss: 0.019832231104373932\n",
      "Epoch 2800 , Loss: 0.03385969623923302\n",
      "Epoch 2900 , Loss: 0.027591165155172348\n",
      "Epoch 3000 , Loss: 0.03642590343952179\n",
      "Epoch 3100 , Loss: 0.006718411576002836\n",
      "Epoch 3200 , Loss: 0.08678402006626129\n",
      "Epoch 3300 , Loss: 0.021476462483406067\n",
      "Epoch 3400 , Loss: 0.024141637608408928\n",
      "Epoch 3500 , Loss: 0.015575411729514599\n",
      "Epoch 3600 , Loss: 0.03868849575519562\n",
      "Epoch 3700 , Loss: 0.007521376479417086\n",
      "Epoch 3800 , Loss: 0.0014980342239141464\n",
      "Epoch 3900 , Loss: 0.007943263277411461\n",
      "Epoch 4000 , Loss: 0.044576287269592285\n",
      "Epoch 4100 , Loss: 0.0017458673100918531\n",
      "Epoch 4200 , Loss: 0.001178072881884873\n",
      "Epoch 4300 , Loss: 0.020622603595256805\n",
      "Epoch 4400 , Loss: 0.020082032307982445\n",
      "Epoch 4500 , Loss: 0.012725278735160828\n",
      "Epoch 4600 , Loss: 0.012278519570827484\n",
      "Epoch 4700 , Loss: 0.0073933228850364685\n",
      "Epoch 4800 , Loss: 0.002268680604174733\n",
      "Epoch 4900 , Loss: 0.011021265760064125\n",
      "Epoch 5000 , Loss: 0.03326377645134926\n",
      "Epoch 5100 , Loss: 0.00459260493516922\n",
      "Epoch 5200 , Loss: 0.014407427981495857\n",
      "Epoch 5300 , Loss: 0.025187088176608086\n",
      "Epoch 5400 , Loss: 0.024205386638641357\n",
      "Epoch 5500 , Loss: 0.00804056040942669\n",
      "Epoch 5600 , Loss: 0.0005378804635256529\n",
      "Epoch 5700 , Loss: 0.0008893145713955164\n",
      "Epoch 5800 , Loss: 0.00034007494105026126\n",
      "Epoch 5900 , Loss: 0.009619438089430332\n",
      "Epoch 6000 , Loss: 0.00010963108798023313\n",
      "Epoch 6100 , Loss: 0.01646408438682556\n",
      "Epoch 6200 , Loss: 0.0020817145705223083\n",
      "Epoch 6300 , Loss: 0.008788645267486572\n",
      "Epoch 6400 , Loss: 0.0003478136204648763\n",
      "Epoch 6500 , Loss: 0.009037921205163002\n",
      "Epoch 6600 , Loss: 0.01245976984500885\n",
      "Epoch 6700 , Loss: 0.0013984469696879387\n",
      "Epoch 6800 , Loss: 0.0011488181771710515\n",
      "Epoch 6900 , Loss: 0.0013192916521802545\n",
      "Epoch 7000 , Loss: 0.01193635631352663\n",
      "Epoch 7100 , Loss: 0.011039067059755325\n",
      "Epoch 7200 , Loss: 0.005643685348331928\n",
      "Epoch 7300 , Loss: 0.0032036546617746353\n",
      "Epoch 7400 , Loss: 0.008741035126149654\n",
      "Epoch 7500 , Loss: 0.0026348333340138197\n",
      "Epoch 7600 , Loss: 0.0010027294047176838\n",
      "Epoch 7700 , Loss: 0.005262730177491903\n",
      "Epoch 7800 , Loss: 0.004568098112940788\n",
      "Epoch 7900 , Loss: 0.0006791849154978991\n",
      "Epoch 8000 , Loss: 0.004134391434490681\n",
      "Epoch 8100 , Loss: 0.003919198643416166\n",
      "Epoch 8200 , Loss: 0.004896658472716808\n",
      "Epoch 8300 , Loss: 0.0016749196220189333\n",
      "Epoch 8400 , Loss: 0.002977465046569705\n",
      "Epoch 8500 , Loss: 0.00020192351075820625\n",
      "Epoch 8600 , Loss: 0.003739594714716077\n",
      "Epoch 8700 , Loss: 0.0024999710731208324\n",
      "Epoch 8800 , Loss: 0.004620644263923168\n",
      "Epoch 8900 , Loss: 0.0008302556816488504\n",
      "Epoch 9000 , Loss: 0.004324872046709061\n",
      "Epoch 9100 , Loss: 0.002165611367672682\n",
      "Epoch 9200 , Loss: 0.00037194520700722933\n",
      "Epoch 9300 , Loss: 0.0025678621605038643\n",
      "Epoch 9400 , Loss: 0.0023290785029530525\n",
      "Epoch 9500 , Loss: 0.002939297817647457\n",
      "Epoch 9600 , Loss: 0.0026050228625535965\n",
      "Epoch 9700 , Loss: 0.002152056898921728\n",
      "Epoch 9800 , Loss: 0.0011663760524243116\n",
      "Epoch 9900 , Loss: 0.0033842362463474274\n",
      "Epoch 10000 , Loss: 0.000983948353677988\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = bpnn(X_batch)\n",
    "        loss = criteon(y_pred, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print(f\"Epoch {epoch+1} , Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值： 8.079035758972168 ， MSE: 0.02121681347489357\n",
      "预测值： 8.338910102844238 ， MSE: 0.020164597779512405\n"
     ]
    }
   ],
   "source": [
    "# 输出验证集结果\n",
    "for X_val, y_val in val_loader:\n",
    "    val_y_pred = bpnn(X_val)\n",
    "    loss = criteon(val_y_pred, y_val)\n",
    "    print(f\"预测值： {scaler.inverse_transform(val_y_pred.detach().numpy())[0][0]} ， \"\n",
    "          f\"MSE: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00502434279769659\n"
     ]
    }
   ],
   "source": [
    "# 计算整体MAPE\n",
    "for X, y in all_loader:\n",
    "    y_pred = bpnn(X)\n",
    "    loss = criteon(y_pred, y)\n",
    "    print(f\"MSE: {loss.item()}\")\n",
    "    result = scaler.inverse_transform(y_pred.detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12015736 0.07131007 0.01908762 0.03981805 0.07182514 0.02847808\n",
      " 0.00988996 0.03716177 0.05250733 0.03816531 0.097943   0.09301337]\n",
      "MAPE:  0.05661308889231296\n"
     ]
    }
   ],
   "source": [
    "# 整体MAPE\n",
    "APE = np.abs(result.reshape(-1) - data.iloc[:, 1].to_numpy()) / data.iloc[:, 1].to_numpy()\n",
    "MAPE = np.mean(APE)\n",
    "print(APE)\n",
    "print(\"MAPE: \", MAPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09547818482944048\n"
     ]
    }
   ],
   "source": [
    "# 后两项MAPE\n",
    "print(np.mean(APE[-2:]))\n",
    "pd.DataFrame(result).to_excel('BPNN_hatx0.xlsx')\n",
    "\n",
    "pd.DataFrame(APE).to_excel('BPNN_APE.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4502, -0.2134],\n",
      "        [-0.0416, -0.3045],\n",
      "        [ 0.0042,  0.1918],\n",
      "        [-0.5546,  0.2929],\n",
      "        [-0.2783,  0.4936],\n",
      "        [-0.2900,  0.1277],\n",
      "        [-0.5207, -0.2343],\n",
      "        [ 0.2976, -0.3975],\n",
      "        [ 0.6222,  0.4245],\n",
      "        [ 0.8049,  0.4589],\n",
      "        [ 0.5750, -0.6856],\n",
      "        [ 0.4247, -0.2020],\n",
      "        [-0.4253, -0.1561],\n",
      "        [ 0.5243,  0.3246],\n",
      "        [ 0.2753, -0.0468],\n",
      "        [ 0.7839, -0.1912]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.2099e-01,  6.1485e-02, -7.0374e-01,  5.8773e-01, -4.8507e-01,\n",
      "         8.5243e-02,  6.2356e-01, -1.6874e-01, -1.3178e-01, -4.3512e-01,\n",
      "        -1.6186e-01, -4.7573e-01,  5.3006e-01,  2.5153e-02, -4.0095e-01,\n",
      "        -7.1931e-06], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1879, -0.0068, -0.2290, -0.0688,  0.0350, -0.1702, -0.0997, -0.1330,\n",
      "          0.1562,  0.0943, -0.1645,  0.1968, -0.1094,  0.0578,  0.2455,  0.1420],\n",
      "        [-0.2436, -0.1448, -0.2190,  0.0030, -0.1047, -0.2097,  0.0477, -0.0278,\n",
      "         -0.2015, -0.1315,  0.1010,  0.1926,  0.2803,  0.1359, -0.0943, -0.2148],\n",
      "        [-0.0394,  0.0117, -0.1540, -0.0903, -0.0682, -0.1379,  0.0763,  0.0441,\n",
      "          0.2678,  0.1174, -0.0901, -0.1365,  0.2010,  0.1361,  0.2107,  0.2019],\n",
      "        [-0.1349, -0.0980, -0.1938, -0.1438,  0.0646, -0.1253,  0.2275, -0.1068,\n",
      "         -0.2715, -0.0545,  0.1427,  0.1808,  0.1875, -0.0205, -0.1119, -0.1811],\n",
      "        [ 0.1362, -0.1256, -0.1888, -0.2313, -0.1108, -0.1849,  0.2214, -0.1835,\n",
      "          0.0170, -0.1610, -0.1545, -0.2121,  0.1286, -0.0313,  0.2318, -0.1668],\n",
      "        [-0.0734, -0.2947, -0.0714, -0.0332,  0.0410,  0.0040, -0.1565, -0.2475,\n",
      "          0.0986,  0.2915, -0.0979, -0.1212,  0.1333,  0.2507, -0.1601, -0.1191],\n",
      "        [-0.0627,  0.1632, -0.1988,  0.0697, -0.2082,  0.0475, -0.0865, -0.0821,\n",
      "          0.0602, -0.2374,  0.2412, -0.2049, -0.0076, -0.0808,  0.2023, -0.1077],\n",
      "        [-0.1530, -0.1341,  0.1290,  0.0574, -0.0781, -0.0712, -0.0202, -0.1026,\n",
      "         -0.0570, -0.2044,  0.2268,  0.2475, -0.0847,  0.1239,  0.0354,  0.0011]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1739,  0.0378,  0.1194,  0.1324, -0.1404,  0.2639, -0.1350,  0.1491],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3351, -0.1485,  0.4017, -0.2657,  0.2176,  0.1413, -0.2836, -0.1446]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2255], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#print(bpnn.fc1.weight)  # 打印权重\n",
    "#print(bpnn.fc1.bias)    # 打印偏置\n",
    "#print(bpnn.fc2.weight)    # 打印偏置\n",
    "#print(bpnn.fc2.bias)    # 打印偏置\n",
    "#print(bpnn.fc3.weight)    # 打印偏置\n",
    "#print(bpnn.fc3.bias)    # 打印偏置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}