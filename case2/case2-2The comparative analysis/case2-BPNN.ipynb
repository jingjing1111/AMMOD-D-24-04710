{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # 导入标准化模块"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# 定义神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # 第一个隐藏层\n",
    "        self.fc2 = nn.Linear(64, 32)           # 第二个隐藏层\n",
    "        self.fc3 = nn.Linear(32, output_size)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"京津冀3省2014-2023使用版数据-2位小数.xlsx\")\n",
    "\n",
    "x, y = data.iloc[:,2:].to_numpy(), data.iloc[:,1].to_numpy().reshape(-1, 1)\n",
    "scaler = MinMaxScaler()  # 实例化\n",
    "X = scaler.fit_transform(x)  # 标准化特征\n",
    "Y = scaler.fit_transform(y)  # 标准化标签\n",
    "\n",
    "train_X, train_Y, val_X, val_Y = X[:-2], Y[:-2], X[-2:], Y[-2:]\n",
    "train_torch_data = TensorDataset(torch.FloatTensor(train_X), torch.FloatTensor(train_Y))\n",
    "val_torch_data = TensorDataset(torch.FloatTensor(val_X), torch.FloatTensor(val_Y))\n",
    "all_torch_data = TensorDataset(torch.FloatTensor(X), torch.FloatTensor(Y))\n",
    "\n",
    "train_loader = DataLoader(train_torch_data, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_torch_data, batch_size=1)\n",
    "all_loader = DataLoader(all_torch_data, batch_size=data.shape[0])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "# 将数据分为输入和输出\n",
    "input_size = 2  # 5个输入\n",
    "output_size = 1  # 1个输出\n",
    "learning_rate = 1e-5 # 学习率\n",
    "\n",
    "bpnn = Net(input_size, output_size)\n",
    "\n",
    "optimizer = optim.Adam(bpnn.parameters(), learning_rate)  # 使用Adam算法更新参数\n",
    "criteon = torch.nn.MSELoss()  # 损失函数，回归问题采用均方误差"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 , Loss: 0.03243058919906616\n",
      "Epoch 200 , Loss: 0.016658086329698563\n",
      "Epoch 300 , Loss: 0.19837889075279236\n",
      "Epoch 400 , Loss: 0.17671440541744232\n",
      "Epoch 500 , Loss: 0.02013644017279148\n",
      "Epoch 600 , Loss: 0.141000434756279\n",
      "Epoch 700 , Loss: 0.13206005096435547\n",
      "Epoch 800 , Loss: 0.12293755263090134\n",
      "Epoch 900 , Loss: 0.02392258495092392\n",
      "Epoch 1000 , Loss: 0.025491736829280853\n",
      "Epoch 1100 , Loss: 0.026092763990163803\n",
      "Epoch 1200 , Loss: 0.020284997299313545\n",
      "Epoch 1300 , Loss: 0.12252125144004822\n",
      "Epoch 1400 , Loss: 0.022963162511587143\n",
      "Epoch 1500 , Loss: 0.09983505308628082\n",
      "Epoch 1600 , Loss: 0.1121002584695816\n",
      "Epoch 1700 , Loss: 0.11707644164562225\n",
      "Epoch 1800 , Loss: 0.03194352611899376\n",
      "Epoch 1900 , Loss: 0.013202950358390808\n",
      "Epoch 2000 , Loss: 0.09555337578058243\n",
      "Epoch 2100 , Loss: 0.028223160654306412\n",
      "Epoch 2200 , Loss: 0.10260731726884842\n",
      "Epoch 2300 , Loss: 0.10711566358804703\n",
      "Epoch 2400 , Loss: 0.09570245444774628\n",
      "Epoch 2500 , Loss: 0.02750147320330143\n",
      "Epoch 2600 , Loss: 0.024263925850391388\n",
      "Epoch 2700 , Loss: 0.027940280735492706\n",
      "Epoch 2800 , Loss: 0.02472115121781826\n",
      "Epoch 2900 , Loss: 0.08330139517784119\n",
      "Epoch 3000 , Loss: 0.09768449515104294\n",
      "Epoch 3100 , Loss: 0.014512108638882637\n",
      "Epoch 3200 , Loss: 0.023402493447065353\n",
      "Epoch 3300 , Loss: 0.03191889822483063\n",
      "Epoch 3400 , Loss: 0.08895456045866013\n",
      "Epoch 3500 , Loss: 0.071634940803051\n",
      "Epoch 3600 , Loss: 0.02281225100159645\n",
      "Epoch 3700 , Loss: 0.019140005111694336\n",
      "Epoch 3800 , Loss: 0.013846817426383495\n",
      "Epoch 3900 , Loss: 0.07658842206001282\n",
      "Epoch 4000 , Loss: 0.07951974868774414\n",
      "Epoch 4100 , Loss: 0.017032314091920853\n",
      "Epoch 4200 , Loss: 0.0660860538482666\n",
      "Epoch 4300 , Loss: 0.020540911704301834\n",
      "Epoch 4400 , Loss: 0.07093028724193573\n",
      "Epoch 4500 , Loss: 0.01263416837900877\n",
      "Epoch 4600 , Loss: 0.07443664968013763\n",
      "Epoch 4700 , Loss: 0.06327590346336365\n",
      "Epoch 4800 , Loss: 0.07243634760379791\n",
      "Epoch 4900 , Loss: 0.030954202637076378\n",
      "Epoch 5000 , Loss: 0.06216811016201973\n",
      "Epoch 5100 , Loss: 0.024814222007989883\n",
      "Epoch 5200 , Loss: 0.05749905854463577\n",
      "Epoch 5300 , Loss: 0.06832675635814667\n",
      "Epoch 5400 , Loss: 0.02437143586575985\n",
      "Epoch 5500 , Loss: 0.054196860641241074\n",
      "Epoch 5600 , Loss: 0.014861811883747578\n",
      "Epoch 5700 , Loss: 0.015011236071586609\n",
      "Epoch 5800 , Loss: 0.02031063660979271\n",
      "Epoch 5900 , Loss: 0.048631880432367325\n",
      "Epoch 6000 , Loss: 0.05145047605037689\n",
      "Epoch 6100 , Loss: 0.04839659482240677\n",
      "Epoch 6200 , Loss: 0.0269312746822834\n",
      "Epoch 6300 , Loss: 0.05132952332496643\n",
      "Epoch 6400 , Loss: 0.04759637638926506\n",
      "Epoch 6500 , Loss: 0.055754441767930984\n",
      "Epoch 6600 , Loss: 0.024268601089715958\n",
      "Epoch 6700 , Loss: 0.04697791486978531\n",
      "Epoch 6800 , Loss: 0.05001280456781387\n",
      "Epoch 6900 , Loss: 0.0578574612736702\n",
      "Epoch 7000 , Loss: 0.04186427965760231\n",
      "Epoch 7100 , Loss: 0.014881745912134647\n",
      "Epoch 7200 , Loss: 0.03431955724954605\n",
      "Epoch 7300 , Loss: 0.023854022845625877\n",
      "Epoch 7400 , Loss: 0.02337132766842842\n",
      "Epoch 7500 , Loss: 0.009429260157048702\n",
      "Epoch 7600 , Loss: 0.03196487948298454\n",
      "Epoch 7700 , Loss: 0.02966444194316864\n",
      "Epoch 7800 , Loss: 0.050175148993730545\n",
      "Epoch 7900 , Loss: 0.030374329537153244\n",
      "Epoch 8000 , Loss: 0.01847001165151596\n",
      "Epoch 8100 , Loss: 0.03156958520412445\n",
      "Epoch 8200 , Loss: 0.005049342755228281\n",
      "Epoch 8300 , Loss: 0.031046390533447266\n",
      "Epoch 8400 , Loss: 0.04042191058397293\n",
      "Epoch 8500 , Loss: 0.008104054257273674\n",
      "Epoch 8600 , Loss: 0.038115017116069794\n",
      "Epoch 8700 , Loss: 0.039653439074754715\n",
      "Epoch 8800 , Loss: 0.03110254369676113\n",
      "Epoch 8900 , Loss: 0.023784788325428963\n",
      "Epoch 9000 , Loss: 0.03380613401532173\n",
      "Epoch 9100 , Loss: 0.025943748652935028\n",
      "Epoch 9200 , Loss: 0.026678768917918205\n",
      "Epoch 9300 , Loss: 0.02567356824874878\n",
      "Epoch 9400 , Loss: 0.03578033298254013\n",
      "Epoch 9500 , Loss: 0.028703592717647552\n",
      "Epoch 9600 , Loss: 0.010547067038714886\n",
      "Epoch 9700 , Loss: 0.01749199628829956\n",
      "Epoch 9800 , Loss: 0.01189490221440792\n",
      "Epoch 9900 , Loss: 0.019868090748786926\n",
      "Epoch 10000 , Loss: 0.011715803295373917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练模型\n",
    "n_epochs = 10000\n",
    "for epoch in range(n_epochs):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = bpnn(X_batch)\n",
    "        loss = criteon(y_pred, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print(f\"Epoch {epoch+1} , Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值： 2.657160520553589 ， MSE: 0.016120092943310738\n",
      "预测值： 2.9305975437164307 ， MSE: 0.1196301132440567\n"
     ]
    }
   ],
   "source": [
    "# 输出验证集结果\n",
    "for X_val, y_val in val_loader:\n",
    "    val_y_pred = bpnn(X_val)\n",
    "    loss = criteon(val_y_pred, y_val)\n",
    "    print(f\"预测值： {scaler.inverse_transform(val_y_pred.detach().numpy())[0][0]} ， \"\n",
    "          f\"MSE: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03177163004875183\n"
     ]
    }
   ],
   "source": [
    "# 计算整体MAPE\n",
    "for X, y in all_loader:\n",
    "    y_pred = bpnn(X)\n",
    "    loss = criteon(y_pred, y)\n",
    "    print(f\"MSE: {loss.item()}\")\n",
    "    result = scaler.inverse_transform(y_pred.detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1347677  0.02298366 0.11201859 0.07384426 0.06425892 0.00317876\n",
      " 0.05364102 0.10934165 0.05321909 0.14260789]\n",
      "MAPE:  0.07698615294783473\n"
     ]
    }
   ],
   "source": [
    "# 整体MAPE\n",
    "APE = np.abs(result.reshape(-1) - data.iloc[:, 1].to_numpy()) / data.iloc[:, 1].to_numpy()\n",
    "MAPE = np.mean(APE)\n",
    "print(APE)\n",
    "print(\"MAPE: \", MAPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09791349027732163\n"
     ]
    }
   ],
   "source": [
    "# 后两项MAPE\n",
    "print(np.mean(APE[-2:]))\n",
    "pd.DataFrame(result).to_excel('BPNN_hatx0-case2.xlsx')\n",
    "\n",
    "pd.DataFrame(APE).to_excel('BPNN_APE-case2.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}